{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using XGBoost in Python\n",
    "\n",
    "XGBoost is one of the most popular machine learning algorithm these days. Regardless of the type of prediction task at hand; regression or classification.\n",
    "XGBoost is well known to provide better solutions than other machine learning algorithms. In fact, since its inception, it has become the \"state-of-the-art” machine learning algorithm to deal with structured data.\n",
    "\n",
    "In this tutorial, you’ll learn to build machine learning models using XGBoost in python. More specifically you will learn:\n",
    "\n",
    "- what Boosting is and how XGBoost operates.\n",
    "- how to apply XGBoost on a dataset and validate the results.\n",
    "- about various hyper-parameters that can be tuned in XGBoost to improve model's performance.\n",
    "- how to visualize the Boosted Trees and Feature Importance\n",
    "\n",
    "But what makes XGBoost so popular?\n",
    "\n",
    "- __Speed and performance__: Originally written in C++, it is comparatively faster than other ensemble classifiers.\n",
    "\n",
    "- __Core algorithm is parallelizable__: Because the core XGBoost algorithm is parallelizable it can harness the power of multi-core computers. It is also parallelizable onto GPU’s and across networks of computers making it feasible to train on very large datasets as well.\n",
    "\n",
    "- __Consistently outperforms other algorithm methods__: It has shown better performance on a variety of machine learning benchmark datasets.\n",
    "\n",
    "- __Wide variety of tuning parameters__: XGBoost internally has parameters for cross-validation, regularization, user-defined objective functions, missing values, tree parameters, scikit-learn compatible API etc.\n",
    "\n",
    "XGBoost (Extreme Gradient Boosting) belongs to a family of boosting algorithms and uses the gradient boosting (GBM) framework at its core. It is an optimized distributed gradient boosting library. But wait, what is boosting? Well, Let's move on to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "Boosting is a sequential technique which works on the principle of an ensemble. It combines a set of weak learners and delivers improved prediction accuracy. At any instant `t`, the model outcomes are weighed based on the outcomes of previous instant `t-1`. The outcomes predicted correctly are given a lower weight and the ones miss-classified are weighted higher. Note that a weak learner is one which is slightly better than random guessing. For example, a decision tree whose predictions are slightly better than `50%` in a binary classification problem. Let's understand boosting in general with a simple illustration.\n",
    "\n",
    "<img src = 'http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1528107577/output_1_0_ilvuyr.png' />\n",
    "\n",
    "Four classifiers (in 4 boxes), shown above, are trying to classify `+` and `-` classes as homogeneously as possible.\n",
    "\n",
    "1. Box 1: The first classifier (usually a decision stump) creates a vertical line (split) at `D1`. It says anything to the left of `D1` is + and anything to the right of `D1` is `-`. However, this classifier misclassifies three `+` points.\n",
    "\n",
    "Note a Decision Stump is a Decision Tree model that only splits off at one level, therefore the final prediction is based on only one feature.\n",
    "\n",
    "2. Box 2: The second classifier gives more weight to the three `+` misclassified points (see the bigger size of `+`) and creates a vertical line at `D2`. Again it says, anything to the right of D2 is `-` and left is `+`. Still, it makes mistakes by incorrectly classifying three `-` points.\n",
    "\n",
    "3. Box 3: Again, the third classifier gives more weight to the three `-` misclassified points and creates a horizontal line at `D3`. Still, this classifier fails to classify the points (in the circles) correctly.\n",
    "\n",
    "4. Box 4: This is a weighted combination of the weak classifiers (Box 1,2 and 3). As you can see, it does a good job at classifying all the points correctly.\n",
    "\n",
    "That's the basic idea behind boosting algorithms is building a **weak** model, making conclusions about the various feature importance and parameters, and then using those conclusions to build a new, **stronger** model and capitalize on the misclassification error of the previous model and try to reduce it. Now, let's come to XGBoost. To begin with, you should know about the default base learners of XGBoost: tree ensembles. The tree ensemble model is a set of classification and regression trees (CART). Trees are grown one after another ,and attempts to reduce the misclassification rate are made in subsequent iterations. [Here’s](https://xgboost.readthedocs.io/en/latest/model.html) a simple example of a CART that classifies whether someone will like computer games straight from the XGBoost's documentation.\n",
    "\n",
    "If you check the image in Tree Ensemble section, you will notice each tree gives a different prediction score depending on the data it sees and the scores of each individual tree are summed up to get the final score.\n",
    "\n",
    "In this tutorial, you will be using XGBoost to solve a regression problem. The dataset is taken from the UCI Machine Learning Repository and is also present in `sklearn`'s `datasets` module. It has `14` features describing various aspects of residential homes in Boston, the challenge is to predict the median value of owner-occupied homes per $1000s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using XGBoost in Python\n",
    "\n",
    "First of all, just like what you do with any other dataset, you are going to import the Boston Housing dataset and store it in a variable called boston. To import it from scikit-learn you will need to run this snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boston variable itself is a `dictionary`, so you can check for its keys using the `.keys()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily check for its shape by using the `boston.data.shape` attribute, which will return the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see it returned `(506, 13)`, that means there are `506` rows of data with `13` columns. Now, if you want to know what the `13` columns are, you can simply use the `.feature_names` attribute and it will return the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description of the dataset is available in the dataset itself. You can take a look at it using `.DESCR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s convert it into a `pandas` DataFrame! For that you need to import the `pandas` library and call the `DataFrame()` function passing the argument `boston.data`. To label the names of the columns, use the `.columnns` attribute of the pandas DataFrame and assign it to `boston.feature_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Do it Yourself\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(boston.data)\n",
    "data.columns = boston.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the top 5 rows of the dataset by using `head()` method on your pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that there is no column called `PRICE` in the DataFrame. This is because the target column is available in another attribute called `boston.target`. Append `boston.target` to your pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['PRICE'] = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `.info()` method on your DataFrame to get useful information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null float64\n",
      "INDUS      506 non-null float64\n",
      "CHAS       506 non-null float64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null float64\n",
      "TAX        506 non-null float64\n",
      "PTRATIO    506 non-null float64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "PRICE      506 non-null float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that this dataset has `14` columns (including the target variable `PRICE`) and `506` rows. Notice that the columns are of float data-type indicating the presence of only __continuous__ features with __no missing__ values in any of the columns. To get more summary statistics of the different features in the dataset you will use the `describe()` method on your DataFrame.\n",
    "\n",
    "Note that `describe()` only gives summary statistics of columns which are continuous in nature and not categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.593761</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.596783</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.647423</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT       PRICE  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plan to use XGBoost on a dataset which has categorical features you may want to consider applying some encoding (like **one-hot encoding**) to such features before training the model. \n",
    "\n",
    "__NOTE__: Like other ML models, XGBoost only works on numerical values\n",
    "\n",
    "Also, if you have some missing values such as `NA` or `NaN` in the dataset you may or may not do a separate treatment for them, because XGBoost is capable of handling missing values internally. You can check out this [link](https://github.com/dmlc/xgboost/issues/21) if you wish to know more on this.\n",
    "\n",
    "Without delving into more exploratory analysis and feature engineering (which we have done multiple times already), you will now focus on applying the algorithm to train the model on this data.\n",
    "\n",
    "You will build the model using Trees as base learners (which are the default base learners) using XGBoost's `scikit-learn` compatible API. Along the way, you will also learn some of the common tuning parameters which XGBoost provides in order to improve the model's performance, and using the **root mean squared error (RMSE)** performance metric to check the performance of the trained model on the test set. Root mean Squared error is the square root of the mean of the squared differences between the actual and the predicted values. As usual, you start by importing the library `xgboost` and other important libraries that you will be using for building the model.\n",
    "\n",
    "Note you can install python libraries like `xgboost` on your system using `pip install xgboost` on cmd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the target variable and rest of the variables using `.iloc` to subset the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = data.iloc[:,:-1],data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will convert the dataset into an optimized data structure called `Dmatrix` that XGBoost supports and gives it acclaimed performance and efficiency gains. You will use this later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost's hyperparameters\n",
    "\n",
    "At this point, before building the model, you should be aware of the tuning parameters that XGBoost provides. Well, there are a plethora of tuning parameters for tree-based learners in XGBoost and you can read all about them here. But the most common ones that you should know are:\n",
    "\n",
    "- `learning_rate`: step size shrinkage used to prevent overfitting. Range is `[0,1]`\n",
    "- `max_depth`: determines how deeply each tree is allowed to grow during any boosting round.\n",
    "- `subsample`: percentage of samples used per tree. Low value can lead to underfitting.\n",
    "- `colsample_bytree`: percentage of features used per tree. High value can lead to overfitting.\n",
    "- `n_estimators`: number of trees you want to build - the more trees you build, the longer the training will be.\n",
    "- `objective`: determines the loss function to be used like `reg:linear` for regression problems, `reg:logistic` for classification problems with only decision, `binary:logistic` for classification problems with probability.\n",
    "\n",
    "XGBoost also supports regularization parameters to penalize models as they become more complex and reduce them to simple (parsimonious) models.\n",
    "\n",
    "- `gamma`: controls whether a given node will split based on the expected reduction in loss after the split. A higher value leads to fewer splits. Supported only for tree-based learners.\n",
    "- `alpha`: L1 regularization on leaf weights. A large value leads to more regularization.\n",
    "- `lambda`: L2 regularization on leaf weights and is smoother than L1 regularization.\n",
    "\n",
    "It's also worth mentioning that though you are using trees as your base learners, you can also use XGBoost's relatively less popular linear base learners and one other tree learner known as dart. All you have to do is set the `booster` parameter to either `gbtree` (default),`gblinear` or `dart`.\n",
    "\n",
    "Now, you will create the train and test set for cross-validation of the results using the `train_test_split` function from sklearn's `model_selection` module with test_size size equal to 20% of the data. Also, to maintain reproducibility of the results, a `random_state` is also assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to instantiate an XGBoost regressor object by calling the `XGBRegressor()` class from the XGBoost library with the hyper-parameters passed as arguments. For classification problems, you would have used the `XGBClassifier()` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the regressor to the training set and make predictions on the test set using the familiar `.fit()` and `.predict()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the `rmse` by invoking the `mean_sqaured_error` function from sklearn's `metrics` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.580319\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, you can see that your `RMSE` for the price prediction came out to be around `3.57` per `$1,000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold Cross Validation using XGBoost\n",
    "In order to build more robust models, it is common to do a k-fold cross validation where all the entries in the original training dataset are used for both training as well as validation. Also, each entry is used for validation just once. XGBoost supports k-fold cross validation via the `cv()` method. All you have to do is specify the `nfolds` parameter, which is the number of cross validation sets you want to build. Also, it supports many other parameters (check out this link) like:\n",
    "\n",
    "- `num_boost_round`: denotes the number of trees you build (analogous to `n_estimators`)\n",
    "- metrics: tells the evaluation metrics to be watched during CV (e.g. RMSE/MSE)\n",
    "- as_pandas: to return the results in a `pandas` DataFrame.\n",
    "- early_stopping_rounds: finishes training of the model early if the hold-out metric (\"rmse\" in our case) does not improve for a given number of rounds - __VERY IMPORTANT TO AVOID OVERFITTING__.\n",
    "- seed: for reproducibility of results - similar to `random_state` so you can retrieve the same folds.\n",
    "\n",
    "This time you will create a hyper-parameter dictionary `params` which holds all the hyper-parameters and their values as key-value pairs but will exclude the `n_estimators` from the hyper-parameter dictionary because you will use `num_boost_rounds` instead.\n",
    "\n",
    "You will use these parameters to build a 3-fold cross validation model by invoking XGBoost's `cv()` method and store the results in a `cv_results` DataFrame. Note that here you are using the Dmatrix object you created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 0 pruned nodes, max_depth=1\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 0 pruned nodes, max_depth=2\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:30:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n"
     ]
    }
   ],
   "source": [
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv_results` contains train and test RMSE metrics for each boosting round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.723922</td>\n",
       "      <td>0.487275</td>\n",
       "      <td>21.737995</td>\n",
       "      <td>1.031725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.813363</td>\n",
       "      <td>0.394578</td>\n",
       "      <td>19.863425</td>\n",
       "      <td>1.073402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.078275</td>\n",
       "      <td>0.302514</td>\n",
       "      <td>18.193932</td>\n",
       "      <td>1.129832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.509690</td>\n",
       "      <td>0.230324</td>\n",
       "      <td>16.673054</td>\n",
       "      <td>1.154620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.160517</td>\n",
       "      <td>0.193297</td>\n",
       "      <td>15.366330</td>\n",
       "      <td>1.200278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0        21.723922        0.487275       21.737995       1.031725\n",
       "1        19.813363        0.394578       19.863425       1.073402\n",
       "2        18.078275        0.302514       18.193932       1.129832\n",
       "3        16.509690        0.230324       16.673054       1.154620\n",
       "4        15.160517        0.193297       15.366330       1.200278"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize how `RMSE` changed over training. You should observe a downward curve below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d2a7b5cf8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "cv_results['test-rmse-mean'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and print the final boosting round metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49    3.871722\n",
      "Name: test-rmse-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print((cv_results[\"test-rmse-mean\"]).tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that your `RMSE` for the price prediction has reduced as compared to last time and came out to be around 3.98 per $1,000. You can reach an even lower RMSE for a different set of hyper-parameters. You may consider applying techniques like **Grid Search**, **Random Search** and **Bayesian Optimization** to reach the optimal set of hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Boosting Trees and Feature Importance\n",
    "You can also visualize individual trees from the fully boosted model that XGBoost creates using the entire housing dataset. XGBoost has a `plot_tree()` function that makes this type of visualization easy. Once you train a model using the XGBoost learning API, you can pass it to the `plot_tree()` function along with the number of trees you want to plot using the `num_trees` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:40:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:40:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:40:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:40:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:40:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:40:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:40:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[00:40:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[00:40:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\n",
      "[00:40:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)\n",
    "\n",
    "xgb.plot_tree(xg_reg,num_trees=0)\n",
    "plt.rcParams['figure.figsize'] = [50, 30]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots provide insight into how the model arrived at its final decisions and what splits it made to arrive at those decisions.\n",
    "\n",
    "Note that if the above plot throws the `graphviz` error on your system, consider installing the graphviz package via `pip install graphviz` on cmd. You may also need to run `sudo apt-get install graphviz` on cmd. (link)\n",
    "\n",
    "Another way to visualize your XGBoost models is to examine the importance of each feature column in the original dataset within the model.\n",
    "\n",
    "One simple way of doing this involves counting the number of times each feature is split on across all boosting rounds (trees) in the model, and then visualizing the result as a bar graph, with the features ordered according to how many times they appear. XGBoost has a `plot_importance()` function that allows you to do exactly this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "xgb.plot_importance(xg_reg)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the feature `B` has been given the highest importance score among all the features. Thus XGBoost also gives you a way to do **Feature Selection**. Isn't this brilliant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You have reached the end of this tutorial. I hope this might have or will help you in some way or the other. You started off with understanding how Boosting works in general and then narrowed down to XGBoost specifically. You also practiced applying XGBoost on an open source dataset and along the way you learned about its hyper-parameters, doing cross-validation, visualizing the trees and in the end how it can also be used as a Feature Selection technique. Whoa!! that's something for starters, but there is so much to explore in XGBoost that it can't be covered in a single tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
